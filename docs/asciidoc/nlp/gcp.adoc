[[nlp-gcp]]
=== Google Cloud Platform (GCP)

[abstract]
--
This chapter describes procedures that wrap Google Cloud Platform's Natural Language API.
--

Google Cloud Platform's https://cloud.google.com/natural-language[Natural Language API^] lets users derive insights from unstructured text using Google machine learning.
The procedures in this chapter act as a wrapper around calls to this API to extract entities, categories, or sentiment from text stored as node properties.

Each procedure has two modes:

* Stream - returns a map constructed from the JSON returned from the API
* Graph - creates a graph or virtual graph based on the values returned by the API

This section includes the following:

* <<nlp-gcp-overview>>
* <<nlp-gcp-dependencies>>
* <<nlp-gcp-api-key>>
* <<nlp-gcp-entities>>
* <<nlp-gcp-classify>>
* <<nlp-gcp-examples>>
    ** <<nlp-gcp-examples-entities>>
    ** <<nlp-gcp-examples-classify>>

[[nlp-gcp-overview]]
==== Procedure Overview

The procedures are described below:

[separator=¦,opts=header,cols="1,1m,1m,5"]
|===
include::../../../build/generated-documentation/apoc.nlp.gcp.entities.csv[]
include::../../../build/generated-documentation/apoc.nlp.gcp.classify.csv[lines=2..3]
|===

[[nlp-gcp-dependencies]]
==== Install Dependencies

include::nlp-dependencies.adoc[]


[[nlp-gcp-api-key]]
==== Setting up API Key

We can generate an API Key that has access to the Cloud Natural Language API by going to https://console.cloud.google.com/apis/credentials[console.cloud.google.com/apis/credentials^].
Once we've created a key, we can populate and execute the following command to create a parameter that contains these details.

.The following defines the `apiKey` parameter
[source,cypher]
----
:param apiKey => ("<api-key-here>")
----

[[nlp-gcp-entities]]
==== Entity Extraction

The entity extraction procedures (`apoc.nlp.gcp.entities.*`) are wrappers around the https://cloud.google.com/natural-language/docs/reference/rest/v1/documents/analyzeEntities[`documents.analyzeEntities`^] method of the Google Natural Language API.
This API method finds named entities (currently proper names and common nouns) in the text along with entity types, salience, mentions for each entity, and other properties.

The procedures are described below:

[separator=¦,opts=header,cols="1,1m,1m,5"]
|===
include::../../../build/generated-documentation/apoc.nlp.gcp.entities.csv[]
|===

The procedures support the following config parameters:

.Config parameters
[opts=header]
|===
| name | type | default | description
| key | String | null | API Key for Google Natural Language API
| nodeProperty | String | text | The property on the provided node that contains the unstructured text to be analyzed
|===

In addition, `apoc.nlp.gcp.entities.graph` supports the following config parameters:

.Config parameters
[opts=header]
|===
| name | type | default | description
| write | Boolean | false | persist the graph of entities
| relationshipType | String | ENTITY | relationship type for relationships from source node to entity nodes
|===

.Streaming mode
[source,cypher]
----
CALL apoc.nlp.gcp.entities.stream(sourceNode:Node, {
  key: String,
  nodeProperty: String
})
YIELD value
----

.Graph mode
[source,cypher]
----
CALL apoc.nlp.gcp.entities.graph(sourceNode:Node, {
  key: String,
  nodeProperty: String,
  relationshipType: String,
  write: Boolean
})
YIELD graph
----


[[nlp-gcp-classify]]
==== Classification

The entity extraction procedures (`apoc.nlp.gcp.classify.*`) are wrappers around the https://cloud.google.com/natural-language/docs/reference/rest/v1/documents/classifyText[`documents.classifyText`^] method of the Google Natural Language API.
This API method classifies a document into categories.

The procedures are described below:

[separator=¦,opts=header,cols="1,1m,1m,5"]
|===
include::../../../build/generated-documentation/apoc.nlp.gcp.classify.csv[]
|===

The procedures support the following config parameters:

.Config parameters
[opts=header]
|===
| name | type | default | description
| key | String | null | API Key for Google Natural Language API
| nodeProperty | String | text | The property on the provided node that contains the unstructured text to be analyzed
|===

In addition, `apoc.nlp.gcp.classify.graph` supports the following config parameters:

.Config parameters
[opts=header]
|===
| name | type | default | description
| write | Boolean | false | persist the graph of entities
| relationshipType | String | CATEGORY | relationship type for relationships from source node to entity nodes
|===

.Streaming mode
[source,cypher]
----
CALL apoc.nlp.gcp.classify.stream(sourceNode:Node, {
  key: String,
  nodeProperty: String
})
YIELD value
----

.Graph mode
[source,cypher]
----
CALL apoc.nlp.gcp.classify.graph(sourceNode:Node, {
  key: String,
  nodeProperty: String,
  relationshipType: String,
  write: Boolean
})
YIELD graph
----


[[nlp-gcp-examples]]
==== Examples

The examples in this section are based on the following sample graph:

[source,cypher]
----
CREATE (:Article {
 uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/",
 body: "These days I’m rarely more than a few feet away from my Nintendo Switch and I play board games, card games and role playing games with friends at least once or twice a week. I’ve even organised lunch-time Mario Kart 8 tournaments between the Neo4j European offices!"
});
----

[[nlp-gcp-examples-entities]]
===== Entity Extraction

Let's start by extracting the entities from the Article node.
The text that we want to analyze is stored in the `body` property of the node, so we'll need to specify that via the `nodeProperty` configuration parameter.

.The following streams the entities for the Pokemon article
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.entities.stream(a, {
  key: $apiKey,
  nodeProperty: "body"
})
YIELD value
UNWIND value.entities AS entity
RETURN entity;
----

.Results
[opts="header"]
|===
| entity
| {name: "card games", salience: 0.17967656, metadata: {}, type: "CONSUMER_GOOD", mentions: [{type: "COMMON", text: {content: "card games", beginOffset: -1}}]}
| {name: "role playing games", salience: 0.16441391, metadata: {}, type: "OTHER", mentions: [{type: "COMMON", text: {content: "role playing games", beginOffset: -1}}]}
| {name: "Switch", salience: 0.143287, metadata: {}, type: "OTHER", mentions: [{type: "COMMON", text: {content: "Switch", beginOffset: -1}}]}
| {name: "friends", salience: 0.13336793, metadata: {}, type: "PERSON", mentions: [{type: "COMMON", text: {content: "friends", beginOffset: -1}}]}
| {name: "Nintendo", salience: 0.12601112, metadata: {mid: "/g/1ymzszlpz"}, type: "ORGANIZATION", mentions: [{type: "PROPER", text: {content: "Nintendo", beginOffset: -1}}]}
| {name: "board games", salience: 0.08861496, metadata: {}, type: "CONSUMER_GOOD", mentions: [{type: "COMMON", text: {content: "board games", beginOffset: -1}}]}
| {name: "tournaments", salience: 0.0603245, metadata: {}, type: "EVENT", mentions: [{type: "COMMON", text: {content: "tournaments", beginOffset: -1}}]}
| {name: "offices", salience: 0.034420907, metadata: {}, type: "LOCATION", mentions: [{type: "COMMON", text: {content: "offices", beginOffset: -1}}]}
| {name: "Mario Kart 8", salience: 0.029095741, metadata: {wikipedia_url: "https://en.wikipedia.org/wiki/Mario_Kart_8", mid: "/m/0119mf7q"}, type: "PERSON", mentions: [{type: "PROPER", text: {content: "Mario Kart 8", beginOffset: -1}}]}
| {name: "European", salience: 0.020393685, metadata: {mid: "/m/02j9z", wikipedia_url: "https://en.wikipedia.org/wiki/Europe"}, type: "LOCATION", mentions: [{type: "PROPER", text: {content: "European", beginOffset: -1}}]}
| {name: "Neo4j", salience: 0.020393685, metadata: {mid: "/m/0b76t3s", wikipedia_url: "https://en.wikipedia.org/wiki/Neo4j"}, type: "ORGANIZATION", mentions: [{type: "PROPER", text: {content: "Neo4j", beginOffset: -1}}]}
| {name: "8", salience: 0, metadata: {value: "8"}, type: "NUMBER", mentions: [{type: "TYPE_UNKNOWN", text: {content: "8", beginOffset: -1}}]}
|===

We get back 12 different entities.
We could then apply a Cypher statement that creates one node per entity and an `ENTITY` relationship from each of those nodes back to the `Article` node.

.The following streams the entities for the Pokemon article and then creates nodes for each entity
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.entities.stream(a, {
  key: $apiKey,
  nodeProperty: "body"
})
YIELD value
UNWIND value.entities AS entity
MERGE (e:Entity {name: entity.name})
SET e.type = entity.type
MERGE (a)-[:ENTITY]->(e)
----

Alternatively we can use the graph mode to automatically create the entity graph.
As well as having the `Entity` label, each entity node will have another label based on the value of the `type` property.
By default a virtual graph is returned.

.The following returns a virtual graph of entities for the Pokemon article
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.entities.graph(a, {
  key: $apiKey,
  nodeProperty: "body",
  relationshipType: "ENTITY"
})
YIELD graph AS g
RETURN g;
----

We can see a Neo4j Browser visualization of the virtual graph in <<apoc.nlp.gcp.entities.graph.svg>>.

[[apoc.nlp.gcp.entities.graph.svg]]
image::apoc.nlp.gcp.entities.graph.svg[title="Pokemon entities graph"]

If we're happy with this graph and would like to persist it in Neo4j, we can do this by specifying the `write: true` configuration.

.The following creates a `HAS_ENTITY` relationship from the article to each entity
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.entities.graph(a, {
  key: $apiKey,
  nodeProperty: "body",
  relationshipType: "HAS_ENTITY",
  write: true
})
YIELD graph AS g
RETURN g;
----

We can then write a query to return the entities that have been created.

.The following returns articles and their entities
[source,cypher]
----
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[:HAS_ENTITY]->(e) | e.name] AS entities;
----

.Results
[opts="header"]
|===
| article                                           | entities
| "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/" | ["tournaments", "Neo4j", "Switch", "card games", "board games", "Mario Kart 8", "Nintendo", "friends", "8", "offices", "European", "role playing games"]
|===

[[nlp-gcp-examples-classify]]
===== Classification

Now let's extract categories from the Article node.
The text that we want to analyze is stored in the `body` property of the node, so we'll need to specify that via the `nodeProperty` configuration parameter.

.The following streams the categories for the Pokemon article
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.classify.stream(a, {
  key: $apiKey,
  nodeProperty: "body"
})
YIELD value
UNWIND value.categories AS category
RETURN category;
----

.Results
[opts="header"]
|===
| category
| {name: "/Games", confidence: 0.91}
|===

We get back only one category
We could then apply a Cypher statement that creates one node per category and a `CATEGORY` relationship from each of those nodes back to the `Article` node.

.The following streams the categories for the Pokemon article and then creates nodes for each category
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.classify.stream(a, {
  key: $apiKey,
  nodeProperty: "body"
})
YIELD value
UNWIND value.categories AS category
MERGE (c:Category {name: category.name})
MERGE (a)-[:CATEGORY]->(c)
----


Alternatively we can use the graph mode to automatically create the category graph.
As well as having the `Category` label, each category node will have another label based on the value of the `type` property.
By default a virtual graph is returned.

.The following returns a virtual graph of categories for the Pokemon article
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.classify.graph(a, {
  key: $apiKey,
  nodeProperty: "body",
  relationshipType: "CATEGORY"
})
YIELD graph AS g
RETURN g;
----

We can see a Neo4j Browser visualization of the virtual graph in <<apoc.nlp.gcp.classify.graph.svg>>.

[[apoc.nlp.gcp.classify.graph.svg]]
image::apoc.nlp.gcp.classify.graph.svg[title="Pokemon categories graph"]

.The following creates a `HAS_CATEGORY` relationship from the article to each entity
[source,cypher]
----
MATCH (a:Article {uri: "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/"})
CALL apoc.nlp.gcp.classify.graph(a, {
  key: $apiKey,
  nodeProperty: "body",
  relationshipType: "HAS_CATEGORY",
  write: true
})
YIELD graph AS g
RETURN g;
----

We can then write a query to return the entities that have been created.

.The following returns articles and their entities
[source,cypher]
----
MATCH (article:Article)
RETURN article.uri AS article,
       [(article)-[:HAS_CATEGORY]->(c) | c.name] AS categories;
----

.Results
[opts="header"]
|===
| article                                                | categories
| "https://neo4j.com/blog/pokegraph-gotta-graph-em-all/" | ["/Games"]
|===